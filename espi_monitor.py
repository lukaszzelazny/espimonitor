import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import os
from dotenv import load_dotenv
import logging
import hashlib
import re
from logging.handlers import RotatingFileHandler

class ESPIMonitor:
    def __init__(self):
        # Za≈Çaduj zmienne ≈õrodowiskowe
        load_dotenv()

        # Konfiguracja logowania
        file_handler = RotatingFileHandler(
            'espi_monitor.log',
            maxBytes=15 * 1024 * 1024,  # 5MB
            backupCount=3
        )

        console_handler = logging.StreamHandler()

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[file_handler, console_handler]
        )
        self.logger = logging.getLogger(__name__)

        # URL strony ESPI
        self.url = "https://espiebi.pap.pl/"

        # Obserwowane sp√≥≈Çki z pliku .env
        watched_companies_str = os.getenv('WATCHED_COMPANIES', '')
        self.watched_companies = [company.strip().upper() for company in
                                  watched_companies_str.split(',') if company.strip()]

        if not self.watched_companies:
            self.logger.warning(
                "Brak obserwowanych sp√≥≈Çek w pliku .env. Dodaj WATCHED_COMPANIES=Dekpol,InnaSp√≥≈Çka")

        # Przechowywanie hashy poprzednich wpis√≥w
        self.previous_entries = set()

        # Konfiguracja sesji HTTP
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })

        self.logger.info(
            f"Monitor ESPI uruchomiony. Obserwowane sp√≥≈Çki: {', '.join(self.watched_companies)}")

    def fetch_page(self):
        """Pobiera zawarto≈õƒá strony ESPI"""
        try:
            response = self.session.get(self.url, timeout=10)
            response.raise_for_status()
            return response.text
        except requests.RequestException as e:
            self.logger.error(f"B≈ÇƒÖd podczas pobierania strony: {e}")
            return None

    def parse_entries(self, html_content):
        """Parsuje HTML i wyciƒÖga wpisy ESPI"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            entries = []

            # Szukamy element√≥w li.news (struktura ESPI)
            news_items = soup.find_all('li', class_='news')

            self.logger.info(f"Znaleziono {len(news_items)} element√≥w li.news")

            for item in news_items:
                try:
                    # Znajd≈∫ link
                    link_elem = item.find('a', class_='link')
                    if not link_elem:
                        continue

                    title = link_elem.get_text(strip=True)
                    link = link_elem.get('href', '')

                    # Znajd≈∫ wszystkie div.hour dla daty
                    hour_divs = item.find_all('div', class_='hour')

                    # WyciƒÖgnij czas z pierwszego div.hour i datƒô/numer z drugiego
                    time_str = ""
                    date_info = ""

                    if len(hour_divs) >= 1:
                        time_str = hour_divs[0].get_text(strip=True)
                    if len(hour_divs) >= 2:
                        date_info = hour_divs[1].get_text(strip=True)

                    # Stw√≥rz datƒô - u≈ºyj dzisiejszej daty + czas z ESPI
                    if time_str and re.match(r'\d{1,2}:\d{2}', time_str):
                        today = datetime.now().strftime('%Y-%m-%d')
                        full_date = f"{today} {time_str}"
                    else:
                        full_date = "Nie znaleziono daty"

                    # Uzupe≈Çnij link
                    if link and not link.startswith('http'):
                        if link.startswith('/'):
                            link = 'https://espiebi.pap.pl' + link
                        else:
                            link = 'https://espiebi.pap.pl/' + link

                    if title and link:
                        entries.append({
                            'title': title,
                            'link': link,
                            'date': full_date,
                            'time_raw': time_str,
                            'date_info_raw': date_info
                        })

                except Exception as e:
                    self.logger.debug(f"B≈ÇƒÖd parsowania elementu: {e}")
                    continue

            self.logger.info(f"Sparsowano {len(entries)} wpis√≥w")
            return entries

        except Exception as e:
            self.logger.error(f"B≈ÇƒÖd podczas parsowania HTML: {e}")
            return []

    def check_company_match(self, title):
        """Sprawdza czy tytu≈Ç zawiera nazwƒô obserwowanej sp√≥≈Çki"""
        title_upper = title.upper()

        for company in self.watched_companies:
            company_upper = company.upper()
            if company_upper in title_upper:
                return company
        return None

    def generate_entry_hash(self, entry):
        """Generuje hash wpisu"""
        content = f"{entry['title']}{entry['link']}"
        return hashlib.md5(content.encode()).hexdigest()

    def process_entries(self, entries):
        """Przetwarza wpisy i sprawdza nowe oraz obserwowane sp√≥≈Çki"""
        new_matches = []
        current_hashes = set()

        for entry in entries:
            entry_hash = self.generate_entry_hash(entry)
            current_hashes.add(entry_hash)

            # Sprawd≈∫ czy nowy wpis
            is_new = entry_hash not in self.previous_entries

            if is_new:
                # Sprawd≈∫ czy dotyczy obserwowanej sp√≥≈Çki
                matched_company = self.check_company_match(entry['title'])
                if matched_company:
                    new_matches.append({
                        'company': matched_company,
                        'title': entry['title'],
                        'link': entry['link'],
                        'date': entry['date']
                    })

        # Aktualizuj poprzednie wpisy
        self.previous_entries = current_hashes
        return new_matches

    def display_matches(self, matches):
        """Wy≈õwietla dopasowania w konsoli"""
        for match in matches:
            print("\n" + "=" * 80)
            print(f"üö® NOWY RAPORT ESPI - {match['company']}")
            print(f"üìã Tytu≈Ç: {match['title']}")
            print(f"üîó Link: {match['link']}")
            print(f"üìÖ Data ESPI: {match['date']}")
            print(f"‚è∞ Wykryto: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("=" * 80 + "\n")

    def run_once(self):
        """Jednorazowe sprawdzenie"""
        self.logger.info("Sprawdzam stronƒô ESPI...")

        html_content = self.fetch_page()
        if not html_content:
            return

        entries = self.parse_entries(html_content)
        if not entries:
            self.logger.warning("Nie znaleziono wpis√≥w")
            return

        matches = self.process_entries(entries)

        if matches:
            self.display_matches(matches)
            self.logger.info(f"Znaleziono {len(matches)} nowych raport√≥w")
        else:
            self.logger.info("Brak nowych raport√≥w dla obserwowanych sp√≥≈Çek")

    def run(self):
        """G≈Ç√≥wna pƒôtla monitorowania"""
        self.logger.info("Uruchamiam monitor ESPI. Ctrl+C aby zatrzymaƒá.")

        # Pierwsze uruchomienie - za≈Çaduj obecne wpisy
        html_content = self.fetch_page()
        if html_content:
            entries = self.parse_entries(html_content)

            matches = self.process_entries(entries)
            if matches:
                self.display_matches(matches)

            for entry in entries:
                entry_hash = self.generate_entry_hash(entry)
                self.previous_entries.add(entry_hash)
            self.logger.info("Za≈Çadowano istniejƒÖce wpisy")

        try:
            while True:
                self.run_once()
                self.logger.info("Czekam 60 sekund...")
                time.sleep(60)
        except KeyboardInterrupt:
            self.logger.info("Monitor zatrzymany")
        except Exception as e:
            self.logger.error(f"B≈ÇƒÖd: {e}")


if __name__ == "__main__":
    monitor = ESPIMonitor()
    monitor.run()